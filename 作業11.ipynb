{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVp-KgUklzm3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "outputId": "9d7a345f-fd60-4073-df72-3814de0ee45d"
      },
      "source": [
        "!pip install opencc-python-reimplemented\n",
        "!wget https://dumps.wikimedia.org/zhwiki/20200301/zhwiki-20200301-pages-articles-multistream1.xml-p1p162886.bz2\n",
        "\n",
        "\n",
        "\n",
        "from gensim.corpora import WikiCorpus\n",
        "\n",
        "wiki_corpus = WikiCorpus('zhwiki-20200301-pages-articles-multistream1.xml-p1p162886.bz2', dictionary={})\n",
        "next(iter(wiki_corpus.get_texts()))[:10]\n",
        "\n",
        "text_num = 0\n",
        "\n",
        "with open('wiki_text.txt', 'w', encoding='utf-8') as f:\n",
        "    for text in wiki_corpus.get_texts():\n",
        "        f.write(' '.join(text)+'\\n')\n",
        "        text_num += 1\n",
        "        if text_num % 10000 == 0:\n",
        "            print('{} articles processed.'.format(text_num))\n",
        "\n",
        "    print('{} articles processed.'.format(text_num))\n",
        "\n",
        "import jieba\n",
        "from opencc import OpenCC\n",
        "\n",
        "\n",
        "# Initial\n",
        "cc = OpenCC('s2t')\n",
        "train_data = open('wiki_text.txt', 'r', encoding='utf-8').read()\n",
        "train_data = cc.convert(train_data)\n",
        "train_data = jieba.lcut(train_data)\n",
        "train_data = [word for word in train_data if word != '']\n",
        "train_data = ' '.join(train_data)\n",
        "open('seg.txt', 'w', encoding='utf-8').write(train_data)\n",
        "\n",
        "from gensim.models import word2vec\n",
        "\n",
        "\n",
        "# Settings\n",
        "seed = 666\n",
        "sg = 0\n",
        "window_size = 10\n",
        "vector_size = 100\n",
        "min_count = 1\n",
        "workers = 8\n",
        "epochs = 5\n",
        "batch_words = 10000\n",
        "\n",
        "train_data = word2vec.LineSentence('seg.txt')\n",
        "model = word2vec.Word2Vec(\n",
        "    train_data,\n",
        "    min_count=min_count,\n",
        "    size=vector_size,\n",
        "    workers=workers,\n",
        "    iter=epochs,\n",
        "    window=window_size,\n",
        "    sg=sg,\n",
        "    seed=seed,\n",
        "    batch_words=batch_words\n",
        ")\n",
        "\n",
        "model.save('word2vec.model')\n",
        "\n",
        "\n",
        "from gensim.models import word2vec\n",
        "\n",
        "string = 'å¾®ç”Ÿç‰©'\n",
        "model = word2vec.Word2Vec.load('word2vec.model')\n",
        "print(string)\n",
        "\n",
        "for item in model.wv.most_similar(string):\n",
        "    print(item)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencc-python-reimplemented\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/0c/c499c86a719c925a08586085a56f92f3235c03ee8b4db2e59c1e9aab3f55/opencc-python-reimplemented-0.1.5.tar.gz (482kB)\n",
            "\r\u001b[K     |▊                               | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 81kB 3.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 112kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 122kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 133kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 143kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 153kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 163kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 174kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 184kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 194kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 204kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 215kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 225kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 235kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 245kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 256kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 266kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 276kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 286kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 296kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 307kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 317kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 327kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 337kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 348kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 358kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 368kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 378kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 389kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 399kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 409kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 419kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 430kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 440kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 450kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 460kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 471kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 481kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 491kB 4.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: opencc-python-reimplemented\n",
            "  Building wheel for opencc-python-reimplemented (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opencc-python-reimplemented: filename=opencc_python_reimplemented-0.1.5-py2.py3-none-any.whl size=485664 sha256=6ff43010525f30d8b7b07c07999879cf288123522356495a02d0cf00c59860bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/a0/10/888b9ac7f10154caaa6a73270b1f085e0a7b241baa672bbe49\n",
            "Successfully built opencc-python-reimplemented\n",
            "Installing collected packages: opencc-python-reimplemented\n",
            "Successfully installed opencc-python-reimplemented-0.1.5\n",
            "--2020-04-23 01:12:01--  https://dumps.wikimedia.org/zhwiki/20200301/zhwiki-20200301-pages-articles-multistream1.xml-p1p162886.bz2\n",
            "Resolving dumps.wikimedia.org (dumps.wikimedia.org)... 208.80.154.7, 2620:0:861:1:208:80:154:7\n",
            "Connecting to dumps.wikimedia.org (dumps.wikimedia.org)|208.80.154.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 172586252 (165M) [application/octet-stream]\n",
            "Saving to: ‘zhwiki-20200301-pages-articles-multistream1.xml-p1p162886.bz2’\n",
            "\n",
            "zhwiki-20200301-pag 100%[===================>] 164.59M  4.45MB/s    in 38s     \n",
            "\n",
            "2020-04-23 01:12:39 (4.38 MB/s) - ‘zhwiki-20200301-pages-articles-multistream1.xml-p1p162886.bz2’ saved [172586252/172586252]\n",
            "\n",
            "10000 articles processed.\n",
            "20000 articles processed.\n",
            "27590 articles processed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.860 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "å¾®ç”Ÿç‰©\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1bb17c607b8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'å¾®ç”Ÿç‰©' not in vocabulary\""
          ]
        }
      ]
    }
  ]
}